{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd235fb0",
   "metadata": {},
   "source": [
    "# Bias Buccaneers Image Recognition Challenge: Quickstart\n",
    "\n",
    "This notebook will introduce you to the data and describe a workflow to train and evaluate a baseline model on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad57b0b7",
   "metadata": {},
   "source": [
    "## Initial Setup\n",
    "\n",
    "We start with loading the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2454f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536f1fd6",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "Make sure to download and uncompress the data (`data_bb1_img_recognition.zip`) in the folder you're working off of.\n",
    "\n",
    "We first load the file containing the labels, binarize labels of each of the three classes as a numpy array and store them as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c742f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "LOADPATH = './train/'\n",
    "SAVEPATH = './models/'\n",
    "df = pd.read_csv(LOADPATH+'labels.csv')\n",
    "df_labeled = df[df[\"skin_tone\"].notna()] # take only labeled data\n",
    "\n",
    "# Converting labels to np array\n",
    "cat = ['skin_tone','gender','age']\n",
    "lbs = [LabelBinarizer() for i in range(3)]\n",
    "Y = []\n",
    "for i in range(3):\n",
    "    lab = lbs[i].fit_transform(df_labeled[cat[i]])\n",
    "    if lab.shape[1]==1:\n",
    "        Y.append(np.hstack((1-lab,lab)))\n",
    "    else:\n",
    "        Y.append(lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb73277",
   "metadata": {},
   "source": [
    "We then load the images under the training set and convert them to numpy arrays. This may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f957a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images\n",
      "Converting images to np array\n"
     ]
    }
   ],
   "source": [
    "# loading and converting data into np array\n",
    "print(\"Loading images\")\n",
    "length = width = 64 # size for each input image, increase if you want\n",
    "nn = df_labeled.shape[0]\n",
    "all_imgs = [image.load_img(LOADPATH+df_labeled.iloc[i]['name'], target_size=(length,width)) for i in range(nn)]\n",
    "\n",
    "print(\"Converting images to np array\")\n",
    "X = np.empty([nn, length, width, 3], dtype=float)\n",
    "for i in range(nn):\n",
    "    X[i,:] = image.img_to_array(all_imgs[i])\n",
    "X = K.applications.resnet50.preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1610c108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F0DB2FBE4E0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_imgs[1234] # print a test image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf14ba8",
   "metadata": {},
   "source": [
    "## Specify the Model\n",
    "\n",
    "We define a single model class that is able train on the data in `X` and `Y` and predict outcomes for all three classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40c55abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionModel():\n",
    "    def __init__(self, X, Y, idx):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.idx = idx\n",
    "        self.trainX, self.testX = X[idx[0],:], X[idx[1],:]\n",
    "        self.trainY, self.testY = [Y[i][idx[0],:] for i in range(3)], [Y[i][idx[1],:] for i in range(3)]\n",
    "        self.cat = ['skin_tone','gender','age']\n",
    "        self.loss = ['categorical_crossentropy' for i in range(3)]\n",
    "        self.metrics = [['accuracy'] for i in range(3)]\n",
    "        self.models = [None]*3\n",
    "\n",
    "    # train a model specific for a certain class index in self.cat\n",
    "    def fit(self, index, model, epochs=5, batch_size=32, save=False, save_location=None, verbose=1):\n",
    "        \n",
    "        if verbose: print(\"Training model for \"+self.cat[index])\n",
    "        model.add(K.layers.Dense(self.trainY[index].shape[1], activation='softmax'))\n",
    "        model.compile(loss=self.loss[index], optimizer='Adam', metrics=self.metrics[index])\n",
    "        model.fit(\n",
    "            self.trainX, self.trainY[index], \n",
    "            validation_data=(self.testX,self.testY[index]), \n",
    "            batch_size=batch_size, epochs=epochs, verbose=verbose\n",
    "        )\n",
    "        if save:\n",
    "            if os.path.exists(SAVEPATH)==False:\n",
    "                print('save location '+SAVEPATH+' did not exist. creating')\n",
    "                os.makedirs(SAVEPATH)\n",
    "            SAVE_LOCATION = save_location+'model_'+cat[index]+'.h5'\n",
    "            print(\"saving model at \"+SAVE_LOCATION)\n",
    "            model.save(SAVE_LOCATION)\n",
    "        self.models[index] = model\n",
    "            \n",
    "    def predict(self, newX):\n",
    "        predictions = [model.predict(newX) for model in self.models]\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76ae9ef",
   "metadata": {},
   "source": [
    "## Initialize and Train a Model\n",
    "\n",
    "We now train a `PredictionModel` to predict the likely skin tone, gender, and age of an input image. This baseline model is initialize on imagenet weights and uses the ResNet50 architecture. We strongly recommend using a GPU to reduce training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da29fedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for skin_tone\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 16s 85ms/step - loss: 2.6600 - accuracy: 0.1320 - val_loss: 4.7888 - val_accuracy: 0.1360\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 2.3338 - accuracy: 0.1710 - val_loss: 2.1001 - val_accuracy: 0.2062\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 15s 77ms/step - loss: 2.1921 - accuracy: 0.1862 - val_loss: 2.0502 - val_accuracy: 0.2241\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 15s 77ms/step - loss: 2.0914 - accuracy: 0.2009 - val_loss: 1.9529 - val_accuracy: 0.2249\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 2.0117 - accuracy: 0.2220 - val_loss: 1.9467 - val_accuracy: 0.2284\n",
      "save location ./models/ did not exist. creating\n",
      "saving model at ./models/model_skin_tone.h5\n",
      "Training model for gender\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 16s 85ms/step - loss: 0.7269 - accuracy: 0.6130 - val_loss: 0.6789 - val_accuracy: 0.7330\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 0.5473 - accuracy: 0.7099 - val_loss: 0.4999 - val_accuracy: 0.7432\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 0.4957 - accuracy: 0.7419 - val_loss: 0.5029 - val_accuracy: 0.7553\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 0.4427 - accuracy: 0.7718 - val_loss: 0.4637 - val_accuracy: 0.7681\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 15s 77ms/step - loss: 0.4198 - accuracy: 0.7885 - val_loss: 0.5197 - val_accuracy: 0.7736\n",
      "saving model at ./models/model_gender.h5\n",
      "Training model for age\n",
      "Epoch 1/5\n",
      "188/188 [==============================] - 16s 85ms/step - loss: 1.4974 - accuracy: 0.3663 - val_loss: 1.3282 - val_accuracy: 0.5413\n",
      "Epoch 2/5\n",
      "188/188 [==============================] - 15s 79ms/step - loss: 1.2276 - accuracy: 0.4732 - val_loss: 1.0369 - val_accuracy: 0.5401\n",
      "Epoch 3/5\n",
      "188/188 [==============================] - 14s 77ms/step - loss: 1.1098 - accuracy: 0.5155 - val_loss: 0.9914 - val_accuracy: 0.5577\n",
      "Epoch 4/5\n",
      "188/188 [==============================] - 15s 78ms/step - loss: 1.0553 - accuracy: 0.5469 - val_loss: 0.9747 - val_accuracy: 0.5705\n",
      "Epoch 5/5\n",
      "188/188 [==============================] - 15s 78ms/step - loss: 0.9993 - accuracy: 0.5727 - val_loss: 0.9679 - val_accuracy: 0.5752\n",
      "saving model at ./models/model_age.h5\n"
     ]
    }
   ],
   "source": [
    "# function to initialize a model\n",
    "def initializeModel():\n",
    "    res_model = ResNet50(include_top=False, weights='imagenet', input_tensor=K.Input(shape=[length,width,3]))\n",
    "\n",
    "    # freeze all but the last layer\n",
    "    for layer in res_model.layers[:143]:\n",
    "        layer.trainable = False\n",
    "    model = K.models.Sequential()\n",
    "    model.add(res_model)\n",
    "    model.add(K.layers.Flatten())\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "    model.add(K.layers.Dense(256, activation='relu'))\n",
    "    model.add(K.layers.Dropout(0.5))\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "    model.add(K.layers.Dense(128, activation='relu'))\n",
    "    model.add(K.layers.Dropout(0.5))\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "    model.add(K.layers.Dense(64, activation='relu'))\n",
    "    model.add(K.layers.Dropout(0.5))\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "    return model\n",
    "\n",
    "nntrain = int(0.7*nn)\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(nn)\n",
    "train_idx, test_idx = indices[:nntrain], indices[nntrain:]\n",
    "mymodel = PredictionModel(X=X, Y=Y, idx=[train_idx,test_idx])\n",
    "\n",
    "# train model\n",
    "for i in range(3):\n",
    "    mymodel.fit(index=i, model=initializeModel(), epochs=5, save=True, save_location=SAVEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6527b5ae",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "\n",
    "We now evaluate the model on the test data. To do this, let's first load up that data and structure it similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43ab27c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting test labels to np array\n",
      "Loading test images\n",
      "Converting test images to np array\n"
     ]
    }
   ],
   "source": [
    "# load labels data\n",
    "TESTPATH = './test/'\n",
    "df_test = pd.read_csv(TESTPATH+'labels.csv')\n",
    "\n",
    "# Convert labels to np array\n",
    "print(\"Converting test labels to np array\")\n",
    "testY = []\n",
    "for i in range(3):\n",
    "    lab = lbs[i].fit_transform(df_test[cat[i]])\n",
    "    if lab.shape[1]==1:\n",
    "        testY.append(np.hstack((1-lab,lab)))\n",
    "    else:\n",
    "        testY.append(lab)\n",
    "        \n",
    "# load and convert images into np array\n",
    "print(\"Loading test images\")\n",
    "nt = df_test.shape[0]\n",
    "all_imgs = [image.load_img(TESTPATH+df_test.iloc[i]['name'], target_size=(length,width)) for i in range(nt)]\n",
    "\n",
    "print(\"Converting test images to np array\")\n",
    "testX = np.empty([nt, length, width, 3], dtype=float)\n",
    "for i in range(nt):\n",
    "    testX[i,:] = image.img_to_array(all_imgs[i])\n",
    "testX = K.applications.resnet50.preprocess_input(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07ee94e",
   "metadata": {},
   "source": [
    "We then obtain predicted labels for skin tone, gender, and age as a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf106302",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mymodel.predict(testX)\n",
    "predY = [[np.argmax(pred[i][j,:]) for j in range(nt)] for i in range(3)]\n",
    "predLabels = [[lbs[i].classes_[j] for j in predY[i]] for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0cf73d",
   "metadata": {},
   "source": [
    "Finally, we calculate the label-wise accuracy and disparity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "081d5cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': {'skin_tone': 0.25766666666666665,\n",
       "  'gender': 0.7966666666666666,\n",
       "  'age': 0.5783333333333334},\n",
       " 'disparity': {'skin_tone': 0.5514223194748359,\n",
       "  'gender': 0.1493182689960596,\n",
       "  'age': 0.7802908824936}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "acc = {}\n",
    "for i in range(3):\n",
    "    icat = cat[i]\n",
    "    iacc = accuracy_score(df_test[cat[i]], predLabels[i])\n",
    "    acc[icat] = iacc\n",
    "\n",
    "# calculate disparity\n",
    "def disparity_score(ytrue, ypred):\n",
    "    cm = confusion_matrix(ytrue,ypred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    all_acc = list(cm.diagonal())\n",
    "    return max(all_acc) - min(all_acc)\n",
    "\n",
    "disp = {}\n",
    "for i in range(3):\n",
    "    icat = cat[i]\n",
    "    idisp = disparity_score(df_test[cat[i]], predLabels[i])\n",
    "    disp[icat] = idisp\n",
    "disp\n",
    "\n",
    "results = {'accuracy': acc, 'disparity': disp}\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20b0fcd",
   "metadata": {},
   "source": [
    "# Score Model and Prepare Submission\n",
    "\n",
    "Based on the above metric, we now calculate the score to evaluate your submission. This score will be displayed in your public leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "db5b9086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'submission_name': '8-Bit Bias Bounty Baseline',\n",
       " 'score': 4.705572543130653,\n",
       " 'metrics': {'accuracy': {'skin_tone': 0.25766666666666665,\n",
       "   'gender': 0.7966666666666666,\n",
       "   'age': 0.5783333333333334},\n",
       "  'disparity': {'skin_tone': 0.5514223194748359,\n",
       "   'gender': 0.1493182689960596,\n",
       "   'age': 0.7802908824936}}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getScore(results):\n",
    "    acc = results['accuracy']\n",
    "    disp = results['disparity']\n",
    "    ad = 2*acc['gender']*(1-disp['gender']) + 4*acc['age']*(1-disp['age']**2) + 10*acc['skin_tone']*(1-disp['skin_tone']**5)\n",
    "    return ad\n",
    "\n",
    "title = '8-Bit Bias Bounty Baseline'\n",
    "    \n",
    "submission = {\n",
    "    'submission_name': title,\n",
    "    'score': getScore(results),\n",
    "    'metrics': results\n",
    "}\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19070a4e",
   "metadata": {},
   "source": [
    "Finally, let's export this as a json file to upload as part of filling out your [submission form](https://docs.google.com/forms/d/e/1FAIpQLSfwqtVkJBVRP6TnFp7vHbbH8SlwKZJFIjvGQy7TyYFc8HR1hw/viewform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34c30e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"baseline_score.json\", \"w\") as f:\n",
    "    json.dump(submission, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
